{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmzuiqianng/GNN_py/blob/main/untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-0LtDgKcal04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-b41ivX3amXM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isxT4rypHUaj",
        "outputId": "79d03858-e099-4ff7-eadd-21060c28f33a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Drive_GNN_200bar/GNN_200bar\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_scatter-2.1.1%2Bpt20cu117-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_sparse-0.6.17%2Bpt20cu117-cp310-cp310-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_cluster-1.6.1%2Bpt20cu117-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_spline_conv-1.2.2%2Bpt20cu117-cp310-cp310-linux_x86_64.whl (885 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m885.5/885.5 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.22.4)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, torch_sparse, torch_cluster\n",
            "Successfully installed torch_cluster-1.6.1+pt20cu117 torch_scatter-2.1.1+pt20cu117 torch_sparse-0.6.17+pt20cu117 torch_spline_conv-1.2.2+pt20cu117\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910460 sha256=d3fe1bc26e64b9aa62e1c6a078a384a37f85b347099c5aac24220347e4489e0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/Drive_GNN_200bar/GNN_200bar'\n",
        "!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFgvlBD2HToT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_geometric\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, ConcatDataset\n",
        "from utils.Creat_GNN_x_edge_Index_disp_Area_label_ import MyEdgeDataset_3\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGPooling, TopKPooling ,GraphUNet\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "import numpy as np\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQ85s7tFJpFi"
      },
      "outputs": [],
      "source": [
        "#把常用的函数放到这里\n",
        "def train():\n",
        "    #常规损失函数训练\n",
        "    model.train()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    loss_run = 0\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "         data = data.to(device)\n",
        "         out = model(data)  # Perform a single forward pass.\n",
        "         #out = out.flatten()\n",
        "         loss = criterion(out, data.label.long() ) # Compute the loss.\n",
        "         #print(loss,out)\n",
        "         # 反向传播和优化\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "\n",
        "         loss_run += loss_run+loss.item()\n",
        "    return loss_run/len(train_loader)\n",
        "\n",
        "def train_best_model(best_accuracy, best_model_params):\n",
        "    #寻找最优model训练\n",
        "    model.train()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    loss_run = 0\n",
        "    #best_accuracy = 0.0\n",
        "    #best_model_params = None\n",
        "\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "        data = data.to(device)\n",
        "        out = model(data)  # Perform a single forward pass.\n",
        "        loss = criterion(out, data.label.long())  # Compute the loss.\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_run += loss.item()\n",
        "\n",
        "    # 计算测试集准确率并保存最优模型\n",
        "    test_accuracy = evaluate_val()\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        best_model_params = model.state_dict()\n",
        "\n",
        "    # 返回训练集平均损失\n",
        "    return loss_run / len(train_loader), best_accuracy, best_model_params\n",
        "\n",
        "def train_save_bestModel(epochs, best_test_accuracy ,best_model, save_best_model=True):\n",
        "    #best_test_accuracy = 0\n",
        "    #best_model = None\n",
        "    #test_accuracy = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "        loss_run = 0\n",
        "        for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "            data = data.to(device)\n",
        "            out = model(data)  # Perform a single forward pass.\n",
        "            loss = criterion(out, data.label.long())  # Compute the loss.\n",
        "\n",
        "            # Backpropagation and optimization.\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_run += loss_run + loss.item()\n",
        "\n",
        "        # Evaluate the model on the test dataset after each epoch.\n",
        "        test_accuracy = evaluate_val()\n",
        "        # If the test accuracy is better than the best accuracy seen so far, save the model.\n",
        "        if save_best_model and test_accuracy > best_test_accuracy:\n",
        "            best_test_accuracy = test_accuracy\n",
        "            best_model = copy.deepcopy(model)\n",
        "        print(f' epoch: {epoch}, Loss: {loss_run / len(train_loader)}, Best_accury: {best_test_accuracy}')\n",
        "\n",
        "    if save_best_model:\n",
        "        return best_model, best_test_accuracy\n",
        "    else:\n",
        "        return loss_run / len(train_loader)\n",
        "\n",
        "def evaluate_train():\n",
        "    #验证训练集的准确率\n",
        "    model.eval()  # 设置为评估模式\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # 在评估过程中不进行梯度计算\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            _, predicted = torch.max(out, 1)\n",
        "            total += data.label.size(0)\n",
        "            correct += (predicted == data.label.long()).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "def evaluate_val():\n",
        "    #评估验证集的准确率\n",
        "    model.eval()  # 设置为评估模式\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # 在评估过程中不进行梯度计算\n",
        "        for data in val_loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            _, predicted = torch.max(out, 1)\n",
        "            total += data.label.size(0)\n",
        "            correct += (predicted == data.label.long()).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "def evaluate_val_optim():\n",
        "    #评估验证集的准确率\n",
        "    model.eval()  # 设置为评估模式\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    correct_epoch = 0\n",
        "    total_epoch = 0\n",
        "    correct_accumulation = 0\n",
        "    total_accumulation = 0\n",
        "    epoch_Acc_data = np.empty((0,1))\n",
        "    accumulation_Acc_data = np.empty((0,1))\n",
        "    epoch = 1\n",
        "    with torch.no_grad():  # 在评估过程中不进行梯度计算\n",
        "        for data in optim_loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            _, predicted = torch.max(out, 1)\n",
        "            #每一步的准确率\n",
        "            total_epoch += data.label.size(0)\n",
        "            correct_epoch += (predicted == data.label.long()).sum().item()\n",
        "            accuracy_epoch = correct_epoch / total_epoch\n",
        "            #累积的准确率\n",
        "            correct_accumulation += (predicted == data.label.long()).sum().item()\n",
        "            total_accumulation += data.label.size(0)\n",
        "            accuracy_accumulation = correct_accumulation / total_accumulation\n",
        "            #将数据拼接进行收集\n",
        "            epoch_Acc_data = np.vstack((epoch_Acc_data, accuracy_epoch))\n",
        "            accumulation_Acc_data = np.vstack((accumulation_Acc_data, accuracy_accumulation))\n",
        "            print('Epoch: ', epoch, ' Accuracy_epoch: ', accuracy_epoch*100, '%', ' Accuracy_accumulation: ', accuracy_accumulation*100, '%')\n",
        "            epoch += 1\n",
        "\n",
        "            correct_epoch = 0\n",
        "            total_epoch = 0\n",
        "\n",
        "\n",
        "    return epoch_Acc_data, accumulation_Acc_data\n",
        "\n",
        "def evaluate_test():\n",
        "    #评估验证集的准确率\n",
        "    model.eval()  # 设置为评估模式\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # 在评估过程中不进行梯度计算\n",
        "        for data in test_loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            _, predicted = torch.max(out, 1)\n",
        "            total += data.label.size(0)\n",
        "            correct += (predicted == data.label.long()).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "xeCz4tBAc_ZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yChA1tB0Jwix",
        "outputId": "e95ba205-c487-414f-c870-6f9eb15de17e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(x=[2000000, 9], edge_index=[2, 18820000], y=[1540000, 2], Area=[290000], label=[10000])\n",
            "10000\n",
            "Data(x=[200, 9], edge_index=[2, 1882], y=[154, 2], Area=[29], label=[1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# 数据集对象操作\n",
        "#dataset = MyEdgeDataset_3(\"./GNN_data/Edge_GNN_AllDisp_data_10bar_Coor_Constrain_lb0_ub35_new_index\") # 创建数据集对象\n",
        "dataset = MyEdgeDataset_3(\"./GNN_data/Edge_GNN_200bar_A_L_constrain_seta_Coor_lb4_ub30\")\n",
        "print(len(dataset))\n",
        "#dataset1用于训练，dataset2用于测试\n",
        "dataset_train = dataset[0:1000]\n",
        "dataset_test = dataset[5000:6000]\n",
        "test_loader = torch_geometric.loader.DataLoader(dataset_test, batch_size=128, shuffle=True)\n",
        "data = dataset[0]\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcYoSuYeJ2lI"
      },
      "outputs": [],
      "source": [
        "class Graph_Unet_class(nn.Module):\n",
        "    def __init__(self,num_features, nhid, lhid, num_classes, pooling_ratio, dropout_ratio):\n",
        "        super(Graph_Unet_class, self).__init__()\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.nhid = nhid\n",
        "        self.num_classes = num_classes\n",
        "        self.lhid = lhid\n",
        "        self.pooling_ratio = pooling_ratio\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "\n",
        "        self.lin0 = nn.Linear(self.num_features,self.nhid )\n",
        "        self.lin0_1 = nn.Linear(self.nhid,self.nhid*2 )\n",
        "\n",
        "        self.conv1 = GCNConv(self.nhid*2, self.lhid)\n",
        "        self.GraphUNet = GraphUNet(in_channels=self.lhid, hidden_channels=self.lhid, out_channels=self.lhid, depth=5, pool_ratios=pooling_ratio)\n",
        "\n",
        "\n",
        "        self.lin1 = nn.Linear(self.lhid*3, self.nhid)\n",
        "        self.lin2 = nn.Linear(self.nhid, self.nhid//2)\n",
        "        self.lin3 = nn.Linear(self.nhid//2, self. num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        #x = x[:, [0,2,3,4,5,6]]\n",
        "\n",
        "        x = F.relu(self.lin0(x))\n",
        "        x = F.relu(self.lin0_1(x))\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        #x, edge_index, _, batch, _ , _ = self.pool1(x, edge_index, None, batch)\n",
        "        #x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = self.GraphUNet(x, edge_index, batch)\n",
        "\n",
        "        x = torch.cat([gmp(x, batch), gap(x, batch), gmp(x, batch)*10 ], dim=1)\n",
        "\n",
        "        #x = torch.cat([x1, x2, x3], dim=1)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.dropout(x, p=self.dropout_ratio, training=self.training)\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.log_softmax(self.lin3(x), dim=-1)\n",
        "        #x = self.lin3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSVBe1VDJ6H5",
        "outputId": "6de694ce-dda0-4f38-8caf-e2d422734f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_number:  800 val_num:  200\n",
            " epoch: 0, Loss: 12.580907038279943, Best_accury: 0.635\n",
            " epoch: 1, Loss: 12.128540311540876, Best_accury: 0.635\n",
            " epoch: 2, Loss: 11.054815573351723, Best_accury: 0.665\n",
            " epoch: 3, Loss: 10.260503453867775, Best_accury: 0.665\n",
            " epoch: 4, Loss: 11.587374355111804, Best_accury: 0.765\n",
            " epoch: 5, Loss: 9.00488269329071, Best_accury: 0.765\n"
          ]
        }
      ],
      "source": [
        "best_test_accuracy_all =torch.zeros(10)\n",
        "model_all = []\n",
        "dataset_train = dataset[0:1000]\n",
        "n_splits = 5\n",
        "datasets_train = random_split(dataset_train, [len(dataset_train)//n_splits]*n_splits)\n",
        "for i in range(n_splits):\n",
        "    #n_splits折交叉验证\n",
        "    train_set = ConcatDataset([d for j,d in enumerate(datasets_train) if j!=i])\n",
        "    valid_set = datasets_train[i]\n",
        "    batch_size = 128\n",
        "    train_loader = torch_geometric.loader.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch_geometric.loader.DataLoader(valid_set, batch_size=batch_size, shuffle=True)\n",
        "    print('train_number: ', len(train_set), 'val_num: ', len(valid_set))\n",
        "    model = Graph_Unet_class(num_features=9, nhid=256, lhid = 256,num_classes=2, pooling_ratio=0.5, dropout_ratio=0.2)\n",
        "\n",
        "\n",
        "    #print(model)\n",
        "    #定义学习率优化器和损失函数\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    best_test_accuracy = 0\n",
        "    best_model = None\n",
        "    epochs = 120\n",
        "    best_model , best_test_accuracy = train_save_bestModel(epochs, best_test_accuracy ,best_model , save_best_model=True)\n",
        "    best_test_accuracy_all[i] = best_test_accuracy\n",
        "    model_all.append(best_model)\n",
        "    #torch.cuda.empty_cache()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19CaeGAKzkZCeeO8PIInv1yCadcrDLo3o",
      "authorship_tag": "ABX9TyP/YhpjGvZzG0phUFirZ6n+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}